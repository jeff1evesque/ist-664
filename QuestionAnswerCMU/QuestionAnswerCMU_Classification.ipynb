{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import tag, word_tokenize\n",
    "from time import time\n",
    "from os import path, makedirs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from utility import normalize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "df1 = pd.read_csv('data/S08/question_answer_pairs.txt', sep='\\\\t', engine='python').dropna()\n",
    "df2 = pd.read_csv('data/S09/question_answer_pairs.txt', sep='\\\\t', engine='python').dropna()\n",
    "df3 = pd.read_csv('data/S10/question_answer_pairs.txt', sep='\\\\t', engine='python').dropna()\n",
    "frames = [df1, df2, df3]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "questions = df['Question']\n",
    "answers = df['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## categorization of penn-tree\n",
    "##\n",
    "## - https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "##\n",
    "penn_scale = {\n",
    "    'CC': 1,\n",
    "    'CD': 2,\n",
    "    'DT': 3, \n",
    "    'EX': 4,\n",
    "    'FW': 5,\n",
    "    'IN': 6,\n",
    "    'JJ': 7,\n",
    "    'JJR': 8,\n",
    "    'JJS': 9,\n",
    "    'LS': 10,\n",
    "    'MD': 11,\n",
    "    'NN': 12,\n",
    "    'NNS': 13,\n",
    "    'NNP': 14,\n",
    "    'NNPS': 15,\n",
    "    'PDT': 16,\n",
    "    'POS': 17,\n",
    "    'PRP': 18,\n",
    "    'PRP$': 19,\n",
    "    'RB': 20,\n",
    "    'RBR': 21,\n",
    "    'RBS': 22,\n",
    "    'RP': 23,\n",
    "    'SYM': 24,\n",
    "    'TO': 25,\n",
    "    'UH': 26,\n",
    "    'VB': 27,\n",
    "    'VBD': 28,\n",
    "    'VBG': 29,\n",
    "    'VBN': 30,\n",
    "    'VBP': 31,\n",
    "    'VBZ': 32,\n",
    "    'WDT': 33,\n",
    "    'WP': 34,\n",
    "    'WP$': 35,\n",
    "    'WRB': 36\n",
    "}\n",
    "\n",
    "def tokenizer(sentence):\n",
    "    '''\n",
    "\n",
    "    penn-tree: tokenize + parts of speech\n",
    "\n",
    "    '''\n",
    "\n",
    "    sent = word_tokenize(sentence)\n",
    "    pos = tag.pos_tag(sent)\n",
    "    return([x[1] for x in pos if x[1] and x[1] in penn_scale])\n",
    "\n",
    "def replace(list, dictionary):\n",
    "    '''\n",
    "\n",
    "    replace list item with corresponding dict value\n",
    "\n",
    "    '''\n",
    "\n",
    "    return [dictionary.get(item, item) for item in list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## order of appending 'pos' (1) must match the order of appending\n",
    "##     the 'sent_type' (2) sentence type.\n",
    "##\n",
    "\n",
    "## (1) pos: combine questions + answers\n",
    "questions_pos = questions.apply(tokenizer)\n",
    "questions_unique = [replace(list(x), penn_scale)  for x in set(tuple(x) for x in questions_pos)]\n",
    "\n",
    "answers_pos = answers.apply(tokenizer)\n",
    "answers_unique = [replace(list(x), penn_scale) for x in set(tuple(x) for x in answers_pos)]\n",
    "\n",
    "## append data\n",
    "pos = answers_unique + questions_unique\n",
    "\n",
    "## (2) sentence type\n",
    "sent_type = []\n",
    "for i in range(len(questions_unique)):\n",
    "    sent_type.append('0')\n",
    "\n",
    "for j in range(len(answers_unique)):\n",
    "    sent_type.append('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adjusted dataset\n",
    "df_adjusted = pd.DataFrame({\n",
    "    'pos': pos,\n",
    "    'type': sent_type\n",
    "})\n",
    "\n",
    "## train + test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_adjusted['pos'],\n",
    "    df_adjusted['type'],\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "## print shape\n",
    "print('X_train: {X}, y_train: {y}'.format(\n",
    "    X=X_train.shape,\n",
    "    y=y_train.shape\n",
    "))\n",
    "\n",
    "print('X_test: {X}, y_test: {y}'.format(\n",
    "    X=X_test.shape,\n",
    "    y=y_test.shape\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stop gap: used for column padding\n",
    "stop_gap = 40\n",
    "\n",
    "## train: ensure nested lists same length\n",
    "length = len(sorted(X_train, key=len, reverse=True)[0])\n",
    "X_train_final=np.array([xi+[stop_gap]*(length-len(xi)) for xi in X_train])\n",
    "X_train_final=pd.DataFrame(X_train_final)\n",
    "\n",
    "## test: ensure nested lists same length\n",
    "length = len(sorted(X_test, key=len, reverse=True)[0])\n",
    "X_test_final=np.array([xi+[stop_gap]*(length-len(xi)) for xi in X_test])\n",
    "X_test_final=pd.DataFrame(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalize datasets\n",
    "X_train_final, X_test_final = normalize_data(X_train_final, X_test_final, stop_gap=stop_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_final.head(10))\n",
    "print(X_test_final.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## random forrest: selected due to high accuracy, and hasn't\n",
    "##     been implemented in the project.\n",
    "##\n",
    "clf=RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "tr0 = time()\n",
    "clf.fit(X_train_final, np.asarray(y_train))\n",
    "tr1 = time()\n",
    "y_pred=clf.predict(X_test_final)\n",
    "tr2 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: {accuracy}'.format(accuracy=accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('random forrest\\ntrain: {rf_train},\\npredict: {rf_predict}'.format(\n",
    "    rf_train=tr1-tr0,\n",
    "    rf_predict=tr2-tr1\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export model\n",
    "if not path.exists('model'):\n",
    "    makedirs('model')\n",
    "joblib.dump(clf, 'model/random_forrest.pkl', compress=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
